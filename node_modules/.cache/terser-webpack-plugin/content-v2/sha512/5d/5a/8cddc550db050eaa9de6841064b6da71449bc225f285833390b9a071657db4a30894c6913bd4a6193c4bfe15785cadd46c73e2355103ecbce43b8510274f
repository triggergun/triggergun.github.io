{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[370],{2113:function(e,t,s){\"use strict\";s.r(t);var a=s(18),r=Object(a.a)({},(function(){var e=this,t=e._self._c;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[t(\"h1\",{attrs:{id:\"ocrs\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#ocrs\"}},[e._v(\"#\")]),e._v(\" Ocrs\")]),e._v(\" \"),t(\"p\",[e._v(\"用于OCR（从图像中提取文本）的Rust库和CLI工具\")]),e._v(\" \"),t(\"p\",[e._v(\"CLI工具是：指命令行工具\")]),e._v(\" \"),t(\"p\",[e._v(\"The goal is to create a modern OCR engine that:\")]),e._v(\" \"),t(\"p\",[e._v(\"目标是创建一个现代OCR引擎，该引擎：\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[t(\"p\",[e._v(\"Works well on a wide variety of images (scanned documents, photos containing text, screenshots etc.) with zero or much less preprocessing effort compared to earlier engines like \"),t(\"a\",{attrs:{href:\"https://github.com/tesseract-ocr/tesseract\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Tesseract\"),t(\"OutboundLink\")],1),e._v(\". This is achieved by using machine learning more extensively in the pipeline.\")]),e._v(\" \"),t(\"p\",[e._v(\"与Tesseract等早期引擎相比，它在各种图像（扫描文档、包含文本的照片、屏幕截图等）上都能很好地工作，预处理工作量为零或少得多。这是通过\"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"在管道中\")]),e._v(\"更广泛地使用机器学习来实现的。\")],1)]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"Is easy to compile and run across a variety of platforms, including WebAssembly\")]),e._v(\" \"),t(\"p\",[e._v(\"易于在各种平台上编译和运行，包括WebAssembly\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"Is trained on open and liberally licensed datasets\")]),e._v(\" \"),t(\"p\",[e._v(\"在开放和自由许可的数据集上接受培训\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"Has a codebase that is easy to understand and modify\")]),e._v(\" \"),t(\"p\",[e._v(\"具有易于理解和修改的代码库\")])])]),e._v(\" \"),t(\"p\",[e._v(\"Under the hood, the library uses neural \"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"network models\")]),e._v(\" trained in \"),t(\"a\",{attrs:{href:\"https://pytorch.org/\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"PyTorch\"),t(\"OutboundLink\")],1),e._v(\", \"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"which\")]),e._v(\" are then exported to \"),t(\"a\",{attrs:{href:\"https://onnx.ai/\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"ONNX\"),t(\"OutboundLink\")],1),e._v(\" and \"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"executed using \")]),e._v(\"the \"),t(\"a\",{attrs:{href:\"https://github.com/robertknight/rten\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"RTen\"),t(\"OutboundLink\")],1),e._v(\" engine. See the \"),t(\"a\",{attrs:{href:\"https://github.com/robertknight/ocrs#models-and-datasets\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"models\"),t(\"OutboundLink\")],1),e._v(\" section for \"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"more details\")]),e._v(\".【跳转到模型部分】\")],1),e._v(\" \"),t(\"p\",[e._v(\"在引擎盖下，该库使用在PyTorch中训练的神经网络模型，然后将其导出到ONNX并使用RTen引擎执行。有关更多详细信息，请参阅模型部分。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"status状态\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#status状态\"}},[e._v(\"#\")]),e._v(\" Status状态\")]),e._v(\" \"),t(\"p\",[e._v(\"ocrs is currently in an early preview. Expect more errors than commercial OCR engines.\")]),e._v(\" \"),t(\"p\",[e._v(\"ocrs目前处于早期预览阶段。预计会出现比商用OCR引擎更多的错误。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"language-support语言支持\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#language-support语言支持\"}},[e._v(\"#\")]),e._v(\" Language Support语言支持\")]),e._v(\" \"),t(\"p\",[e._v(\"ocrs currently recognizes the Latin alphabet only (eg. English). Support for more languages is \"),t(\"a\",{attrs:{href:\"https://github.com/robertknight/ocrs/issues/8\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"planned\"),t(\"OutboundLink\")],1),e._v(\".\")]),e._v(\" \"),t(\"p\",[e._v(\"ocrs目前只识别拉丁字母（如英语）。计划支持更多语言。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"cli-installation命令行安装\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#cli-installation命令行安装\"}},[e._v(\"#\")]),e._v(\" CLI installation命令行安装\")]),e._v(\" \"),t(\"p\",[e._v(\"To install the CLI tool, you will first need Rust and Cargo installed. Then run:\")]),e._v(\" \"),t(\"p\",[e._v(\"要安装CLI工具，您首先需要安装Rust和Cargo。然后运行：\")]),e._v(\" \"),t(\"p\",[e._v(\"第一步：安装Rust和Cargo请见：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language-shell line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[t(\"code\",[e._v(\"$ \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[e._v(\"cargo\")]),e._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[e._v(\"install\")]),e._v(\" ocrs-cli\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"cli-usage命令行的使用\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#cli-usage命令行的使用\"}},[e._v(\"#\")]),e._v(\" CLI usage命令行的使用\")]),e._v(\" \"),t(\"p\",[e._v(\"To extract text from an image, run:\")]),e._v(\" \"),t(\"p\",[e._v(\"要从图像中提取文本，请运行：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language-shell line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[t(\"code\",[e._v(\"$ ocrs image.png\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"p\",[e._v(\"When the tool is run for the first time, it will download the required models automatically and store them in \"),t(\"code\",[e._v(\"~/.cache/ocrs\")]),e._v(\".\")]),e._v(\" \"),t(\"p\",[e._v(\"当该工具首次运行时，它将自动下载所需的模型并将其存储在“~/.cache/ocrs”中。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"additional-examples其他示例\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#additional-examples其他示例\"}},[e._v(\"#\")]),e._v(\" Additional examples其他示例\")]),e._v(\" \"),t(\"p\",[e._v(\"Extract text from an image and write to \"),t(\"code\",[e._v(\"content.txt\")]),e._v(\":\")]),e._v(\" \"),t(\"p\",[e._v(\"从图像中提取文本并写入“content.txt”：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"$ ocrs image.png -o content.txt\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"p\",[e._v(\"Extract text and layout information from the image in JSON format:\")]),e._v(\" \"),t(\"p\",[e._v(\"以JSON格式从图像中提取文本和布局信息：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"$ ocrs image.png --json -o content.json\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"p\",[e._v(\"Annotate an image to show the location of detected words and lines:\")]),e._v(\" \"),t(\"p\",[e._v(\"注释图像以显示检测到的单词和线条的位置：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"$ ocrs image.png --png -o annotated.png\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"library-usage库的使用\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#library-usage库的使用\"}},[e._v(\"#\")]),e._v(\" Library usage库的使用\")]),e._v(\" \"),t(\"p\",[e._v(\"See the \"),t(\"a\",{attrs:{href:\"https://github.com/robertknight/ocrs/blob/main/ocrs\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"ocrs crate README\"),t(\"OutboundLink\")],1),e._v(\" for details on how to use ocrs as a Rust library.\")]),e._v(\" \"),t(\"p\",[e._v(\"有关如何将ocrs用作Rust库的详细信息，请参阅ocrs crate README。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"models-and-datasets模型和数据集\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#models-and-datasets模型和数据集\"}},[e._v(\"#\")]),e._v(\" Models and datasets模型和数据集\")]),e._v(\" \"),t(\"p\",[e._v(\"ocrs uses neural network models written in PyTorch. See the \"),t(\"a\",{attrs:{href:\"https://github.com/robertknight/ocrs-models\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"ocrs-models\"),t(\"OutboundLink\")],1),e._v(\" repository for more details about the models and datasets, as well as tools for training custom models. These models are also available in ONNX format for use with other machine learning runtimes.\")]),e._v(\" \"),t(\"p\",[e._v(\"ocrs使用 \"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"PyTorch编写的神经网络模型\")]),e._v(\"。有关模型和数据集的更多详细信息，以及 \"),t(\"font\",{attrs:{color:\"red\"}},[e._v(\"训练自定义模型的工具\")]),e._v(\"，请参阅ocrs模型存储库。\")],1),e._v(\" \"),t(\"p\",[e._v(\"这些模型也有ONNX格式，可用于其他机器学习运行时。\")]),e._v(\" \"),t(\"h2\",{attrs:{id:\"development部署\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#development部署\"}},[e._v(\"#\")]),e._v(\" Development部署\")]),e._v(\" \"),t(\"p\",[e._v(\"To build and run the ocrs library and CLI tool locally you will need a recent stable Rust version installed. Then run:\")]),e._v(\" \"),t(\"p\",[e._v(\"要在本地构建和运行ocrs库和CLI工具，您需要安装最新稳定的Rust版本。然后运行：\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"git clone https://github.com/robertknight/ocrs.git\\ncd ocrs\\ncargo run -p ocrs-cli -r -- image.png\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"testing测试\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#testing测试\"}},[e._v(\"#\")]),e._v(\" Testing测试\")]),e._v(\" \"),t(\"p\",[e._v(\"Ocrs has unit tests for the code that runs before and after ML model processing, plus E2E tests which exercise the whole pipeline, including models.\")]),e._v(\" \"),t(\"p\",[e._v(\"After making changes to the code, run unit tests and lint checks with:\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"make check\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"p\",[e._v(\"You can also run standard commands like \"),t(\"code\",[e._v(\"cargo test\")]),e._v(\" directly.\")]),e._v(\" \"),t(\"p\",[e._v(\"Run the E2E tests with:\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v(\"make test-e2e\\n\")])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\")])]),t(\"p\",[e._v(\"For details of how the ML models are evaluated, see the \"),t(\"a\",{attrs:{href:\"https://github.com/robertknight/ocrs-models\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"ocrs-models\"),t(\"OutboundLink\")],1),e._v(\" repository.\")])])}),[],!1,null,null,null);t.default=r.exports}}]);","extractedComments":[]}